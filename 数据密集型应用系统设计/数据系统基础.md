# 数据密集型应用系统设计

# 数据系统基础

### 数据密集型应用系统原则

- 数据密集型
- 计算密集型

### 系统模块

- 数据库
- 高速缓存
- 索引
- 流式处理
- 批处理

## P1. 可靠、可扩展和可维护的应用系统

- 可靠性
    - 容错针对特定类型的故障才更有实际意义。
    - 多机冗余对于一些关键应用，保证其高可用绝对是有必要的。
    - 软件容错作为硬件容错的补充
    - 假设人是不可靠的
    - 测试环境以及测试用例
    - 发布系统 及时回滚
    - 监控系统
- 可扩展性
    - 描述负载
    - 描述性能
    - 扇出结构
    - 拆分读写性能
    - 垂直扩展 水平扩展 针对有状态服务和无状态服务区分
        - 将数据库运行在一个节点（垂直扩展策略） 直接高扩展性和高可用性的要求破事不得不做水平扩展
        - 超大规模的系统往往针对特定应用而高度定制
- 可维护性
    - 可维护性 监控、自动化、服务发现等
    - 简化复杂度
        - 模块紧耦合
        - 相互依赖
        - 不一致的命名和术语
        - 为了性能or需求做特殊处理
        - 解决特定问题引入特殊框架
        - …
    - 抽象
    - 可演化性：数据系统级的敏捷性

## P2. 数据模型与查询语言

- 复杂的应用程序有更多的中间层，每层都通过提供一个简洁的数据模型来隐藏下层的复杂性

### 关系模型

- 目标是将实现细节隐藏在简洁的接口下面
- 使用id的好处，他对人类没有任何直接意义
- 定义了所有数据的格式
- 具体的查询逻辑由查询优化器自动生成，不是由开发人员维护
- 关系模型的核心：只需要构建一次查询优化器，然后使用该数据库的所有应用程序都可以从中受益

### 文档模型

- 一对多的树状结构不需要联接，对联结的支持很弱
- 联结的工作从数据层转移到了应用层

### 对比

- 支持文档数据模型的主要论点是模式灵活性，由于局部性而带来较好的性能，对于某
些应用来说，它更接近于应用程序所使用的数据结构。
- 关系模型则强在联结操作，多对一和多对多关系更简洁的表达上，与文档模型抗衡。

### 声明式查询语言

- SQL
- 只需要指定所需的数据模型，不需要指明如何实现这一目标
- 适合并行执行

### 命令式查询语言

- 告诉计算机以特定的顺序执行某些操作

### MapReduce查询

- map和reduce西数对于可执行的操作有所限制。它们必须是純函数，这意味着只能使
用传递进去的数据作为输人，而不能执行额外的数据库查询，也不能有任何副作用。
这些限制使得数据库能够在任何位置、以任意顺序来运行函数，并在失败时重新运行
这些函数。不管怎样，该功能非常强大，可以通过它来解析字符串、调用库函数、执
行计算等。
- MapReduce是一个相当底层的编程模型，用王在让算集群上分布执行。而SQL这样的
更高层次的查询语言可以通过一些MapReduce操作pipeline来实现

## P3.数据存储与检索

- 数据库只需要做两件事，向它插入数据是，它就保存数据；查询时返回那些数据

### 数据结构（数据库的核心）

- 日志机制
- 索引
    
    基于原始数据派生而来的额外数据结构。
    
    很多数据库允许单独添加和删除索引，而不影响数据库的内容，它只会影响查询性能。
    
    维护额外的结构势必会引入开销，任何类型的索引通常都会降低写的速度
    
    适当的索引可以加速读取查询，但每个索引都会减慢写速度。为此，默认情况下，数据库通常不会对所有内容进行索引
    
    **哈希索引**
    
    Kex-value类型并不是唯一可以索引的数据，但它随处可见，而且是其他更复杂索引的基础构造模块
    
    局限性：必须全部放入内存；区间查询效率不高
    

### 段

段在写入后不会进行修改，合并的段会被写入一个新文件，每个段都有自己的内存哈希表

- 为什么不原地更新，新值覆盖旧值，而是追加？
    
    追加和分段合并主要是顺序写，它通常比随机写入快得多，特别是在旋转式磁
    性硬盘上。在某种程度上，顺序写入在基于闪存的固态硬盘 (solid state drives,
    SSD）上也是适合的。
    
    如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。例如，不必担
    心在重写值时发生崩溃的情况，留下一个包含部分旧值和部分新值混杂在一起的
    文件。
    合并旧段可以避免随着时间的推移数据文件出现碎片化的问题。
    

### SSTable和LSM-Tree

- 合并段更加高效，多路合并
- 查找特定键更高效，不需要内存保存全部的键，可以稀疏

存储引擎的工作流程

- 类似lucene写入 略

### B-Trees

### 对比B-Tree和LSM_Tree

- p84

### 事务处理和分析处理

- LOLTP和OLAP
- 列式存储
    - 非常适合压缩 列压缩

### 总结

- p101

## P4. 数据编码和演化

- 新旧数据兼容问题

### 两种不同的数据表现形式

- 在**内存**中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些
数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）
- 将**数据写入文件或通过网络发送**时：必须将其编码为某种自包含的字节序列（例
如JSON文档）。由于指针对其他进程没有意义，所以这个字节序列表示看起来
与内在中使用的数据结构大不一样

### 模式的优点

- p124

### REST和RPC的对比，优劣

- p127

# 分布式系统

### 复制

同步  主节点阻塞后会导致整个系统更新停滞

半同步

全异步 不管数据多滞后，不会影响线上吞吐量，异步复制使用较多，但是会有复制滞后的问题

节点切换

- 确认失效 超时机制
- 选举的方式达成共识，选举主节点
- 重新配置使主节点生效，原主节点降为从节点

复制滞后问题：

- 最终一致性
- **读自己的写 用户自己读取主节点配置，其他读取从节点**
- **根据更新时间：最近一分钟主节点，其他读取从节点**
- 客户端记住更新的时间戳，对比节点的时间戳，不够新的话换个节点
- **单调读一致性 确保每个用户总是从固定的一个副本读取**

避免写冲突

- 主从节点
- 乐观锁
- 事务
- 依靠应用层

quorom一致性 更低的延迟和更高的可用性

### 分区

- 数据倾斜 热点问题：
    - 随机分配到所有节点，但不知道特定数据位置，需要并行查所有节点
    - 基于关键字分区 时间戳+关键字
    - 关键字hash分区
    - 通过应用层
- 基于词条的二级索引分区
    - 词条分区 读取高效 写入慢 复杂
    - 文档分区：

### 事务

- acid 原子性、一致性、隔离性和持久性
- 一致性更多的是应用层的属性
- 隔离性多个并发相互隔离
- 原子性（要么全部成功，要么全部失败）和隔离性（多个事务互不打扰）

弱隔离级别

- 读提交 防止脏读（只能看到提交成功的数据）和脏写（只会覆盖成功提交的数据）
- 推迟第二个操作的写请求，直接前面的事务完成提交、
- 不能解决更新丢失的问题

快照级别隔离和可重复读

- 从数据库的一致性快照中读取，一开始看到的都是最近提交的数据
- 多版本并发控制

防止更新丢失

- 原子写操作
- 显式加锁
- 自动检测更新丢失

写倾斜

幻读 一个事务的写入改变了另一个事务查询结果

串行化

- 两阶段加锁 可以同时读取同一个对象，但只要写操作，就需要加锁。读取时共享锁，写入时独占锁

### 分布式的挑战

- 部分失效
- 网络不可靠
    - 现实中的故障
    - 同步异步更新问题
    - 超时设置
- 时钟不可靠
    - 绝对时间
    - 相对时间
- 进程暂停 垃圾回收 stw
- 共识问题
- 拜占庭故障

### 一致性与共识

共识意味着所有节点做出一致决定，且不可撤销

最终一致性

- 可线性化
    - 牺牲性能，返回读结果之前，进行读修复，写入之前，获取最新值
- 顺序保证
    - 因果一致性
    - 序列号排序
- 全序关系广播
    - 可靠发送
    - 严格有序
    - 需要共识服务 zookeeper或etcd
    - 异步模型，不保证消息何时发送成功，但是有序

分布式事务与共识

- 原子提交
- 两阶段提交
    - 协调者负责确认和写入
    - 写入失败一直重试
    - 写入事务日志

成员与协调服务

- 线性化的原子操作 cas比较交换的原子操作实现加锁，到期租约实现释放
- 操作全序 递增的事务id版本号
- 故障检测 交换心跳
- 更改通知

节点失效问题

- 超时时间
- 节点投票
- 协调节点执行跨节点的协调服务，包括失效、新增、故障恢复、负载均衡等

网络不可靠问题

- 心跳检测
- 节点投票

副本一致性问题

- 协调配置服务，配置数据 少量，可完全载入内存，通过容错的全序广播算法在所有节点上实现复制，到达高可用
- 全序广播主要用来实现数据库复制：每条消息代表数据库写请求，按照相同的顺序在多个节点执行写操作，达到多副本一致性

因果一致性提供了弱一致性模型，允许并发，时间线上可以包含多个分支，保证当前的因果关系，避免了协调开销，对网络延迟敏感性要低很多

主节点故障三种情况

- 重启
- 人工选择
- 依靠共识算法自动选择

# 异构系统的派生数据

**记录系统拥有数据的权威版本**

派生系统 从另一个系统中获取已有数据，并进行转换或处理，对于获取良好的读取查询性能至关重要

**批处理系统，全量任务 衡量指标 吞吐量**

**流处理系统，增量任务 延迟**

顺序io在磁盘上有更好的性能表现

### unix哲学 适合中间件

- 每个程序做好一件事
- 每个程序的输出成为另一个尚未确定的程序的输入
- 建造尝试设计和构建软件，甚至是操作系统
- 优先使用工具减轻编程任务

分布式文件系统 HDFS 无共享原则，不需要定制的硬件和特殊的网络，只需要通过传统数据中心网络连接的计算机

mapreduce

mapper负责对文档进行分区，每个reducer构建其分区索引，并将索引文件写入分布式文件系统，并行处理

**无状态数据，带来的副作用：每次任务失败都需要重试 多任务并行重试的成本更高，串行更容错**

在unix世界中，允许多个程序组合在一起的统一接口是文件和管道，在mapreduce中，该接口是分布式文件系统

### 流处理系统

一种数据管理机制：无界、持续增量的处理方式。

由事件生产者生产一次，然后由多个消费者（订阅者）处理，流系统中，相关的事件被组合成主题或者流

1. 生产这发送消息比消费者处理的快？
    1. 系统丢弃
    2. 缓存在队列中
    3. 激活背压即流量控制，阻止生产者发送更多的消息
2. 节点崩溃or暂时离线，是否会有消息丢失
    1. 持久性需要写入磁盘或者结合复制方案，都是有成本的，如果能够接受丢失消息，意味着更大的吞吐量和更低的延迟

**消息代理（消息队列）实际是一种针对消息流而优化的数据库。**

消费者以异步方式处理，生产者发送消息只保证代理已经确认缓存的消息，而不会等待消息被处理，消费者的交付会在未来不确定的时间，有时队列积压会产生延迟

**消息代理和数据库的对比**

- 数据库会保留数据直至明确被删除，大部分消息代理在消息成功传递给消费者后会自动删除，或者设置保留日期，不合适长期存储数据
- 消息系统会假定数据集很小，如果因为消费者很慢需要缓存消息时并且内存无法容纳时，会将部分消息保存到磁盘，影响吞吐量
- 数据库支持二级索引等查询方式，消息代理支持订阅匹配的主题的方式。
- 消息队列不支持任意类型的查询，只是在有新消息时会通知客户端

**多个消费者：扇出式，负载均衡式，可以组合使用**

**基于日志的消息存储，完全有序，使用消息像读取文件，只读操作。通过分区实现并行**

**消息代理的行为像一个主节点的数据库，消费者是从节点**

**代理不需要跟踪每条消息的确认，只需要定期记录消费者的偏移量，减少了记录开销，提高系统的吞吐量**

**日志实现了大小有限的缓冲区，满了之后旧数据就被丢弃掉**

**每个消息都被写入到磁盘，日志的吞吐量基本保持不变，相比较消息默认在内存中，当写入磁盘之后会变得很慢。**

**保持系统同步：**

1. **双写，写入数据库之后，写入缓存更新**
2. **变更数据捕获，日志消息代理保留了消息的排序，也会有复制滞后的问题**

**数据压缩：只保留每个key（操作日志行为）的最新的更新**

**在流上搜索，es的过滤器功能：保存查询条件，每条文档流过查询条件**

流式join：流和流（定义join窗口）流和表join，表和表join

**幂等性**