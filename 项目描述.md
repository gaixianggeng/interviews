### 搜索召回服务
* 基于现成的doc，百科id+title
* 构建倒排表，通过类似lucene写入方式，段写入，段合并，b+数构建字典，倒排表使用lsmtree的方式顺序写入
* 相关性 tfidf bm25
* ngram分析 验证效果
* 召回也是多段召回，每个segment对应一个字段数据库

### 重构索引服务
* 两套索引服务
* 一套做索引任务，一套用于线上服务
* 每一套都是多节群，通过redis key切换
* 数据流构建索引文件+索引写入耦合严重。
新版支持
1. 支持服务发现，数据节点切换上游无感知
2. 索引层解耦 数据批处理层+索引index层
3. 索引文件ok 上游服务ok，只剩index任务
4. 之前index 每个集群bulk方式向批量写入
5. 耗时 index， 先写入一个集群，构建倒排数据，其他集群es snapshot restore方式，基于hdfs方式，同拓扑，每个es节点对应一个hdfs分区，相当于局域网内传输复制文件，没有其他构建倒排等流程，写一个集群2h，现在15min。全量变批量，没有多集群上下线的操作，只有单集群在服务发现上的注册与取消
6. 为什么不每个集群部署一个写入服务，运维成本太高，一旦失败就要重跑，对应的监控体系不够完善
7. 深度定制服务发现规则，出现yellow下掉该节点，yellow数量过多的时候，不再下掉，即一开始根据green+ping作为判活标准，超过一半之后，改为yellow+ping